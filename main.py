"""
ä¸»ç¨‹åº - GPUé«˜åˆ©ç”¨ç‡Whisperè½¬å½•åº”ç”¨
é‡æ„åçš„æ¨¡å—åŒ–ç‰ˆæœ¬
"""
import gradio as gr
import torch

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from config.config import OPTIMIZED_MODELS, APP_TITLE, APP_PORT, MAX_FILE_SIZE, DEEPSEEK_API_KEY
from src.utils import get_gpu_info, monitor_gpu_usage
from src.whisper_model import transcribe_high_utilization, clear_all_cache
from src.ai_summary import summarize_with_deepseek
from src.file_operations import save_transcript_with_dialog, save_summary_with_dialog
from src.ui_components import create_system_status_html, create_api_status_components, create_performance_info

def main():
    """ä¸»å‡½æ•°"""
    # ç³»ç»Ÿä¿¡æ¯
    gpu_available, gpu_name, gpu_memory = get_gpu_info()
    print(f"GPU: {gpu_name} ({gpu_memory})")
    print(f"Device: {'cuda:0' if torch.cuda.is_available() else 'cpu'}")
    
    # åˆ›å»ºç•Œé¢
    with gr.Blocks(title=APP_TITLE, theme=gr.themes.Monochrome()) as demo:
        gr.Markdown("# âš¡ GPUé«˜åˆ©ç”¨ç‡Whisperè½¬å½•")
        
        # ç³»ç»ŸçŠ¶æ€
        gr.HTML(create_system_status_html())
        
        with gr.Row():
            with gr.Column():
                # è§†é¢‘ä¸‹è½½æç¤º
                gr.HTML("""
                <div style="padding: 10px; background-color: #f0f8ff; border-radius: 5px; margin-bottom: 15px; border-left: 4px solid #007acc;">
                    <p style="margin: 0; color: #333;">
                        ğŸ’¡ <strong>éœ€è¦ä¸‹è½½åœ¨çº¿è§†é¢‘ï¼Ÿ</strong> 
                        <a href="https://dy.kukutool.com/" target="_blank" style="color: #007acc; text-decoration: none;">
                            ç‚¹å‡»è¿™é‡Œè®¿é—®è§†é¢‘è§£æå·¥å…· â†’
                        </a>
                    </p>
                    <small style="color: #666;">æ”¯æŒæŠ–éŸ³ã€Bç«™ã€å°çº¢ä¹¦ç­‰å¹³å°ï¼Œä¸‹è½½åç›´æ¥ä¸Šä¼ å³å¯</small>
                </div>
                """)
                
                # æ–‡ä»¶ä¸Šä¼ 
                audio_input = gr.File(
                    label="ğŸ“ ä¸Šä¼ éŸ³è§†é¢‘æ–‡ä»¶",
                    file_types=["audio", "video"]
                )
                
                # ä¼˜åŒ–æ¨¡å‹é€‰æ‹©
                model_input = gr.Dropdown(
                    choices=list(OPTIMIZED_MODELS.keys()),
                    value="Medium (é«˜åˆ©ç”¨ç‡)",
                    label="ğŸ¤– é€‰æ‹©GPUä¼˜åŒ–æ¨¡å‹",
                    info="æ‰€æœ‰æ¨¡å‹éƒ½é’ˆå¯¹é«˜åˆ©ç”¨ç‡ä¼˜åŒ–"
                )
                
                # è¯­è¨€
                language_input = gr.Dropdown(
                    choices=[("ä¸­æ–‡", "chinese"), ("è‹±è¯­", "english"), ("è‡ªåŠ¨", "auto")],
                    value="chinese",
                    label="ğŸŒ è¯­è¨€"
                )
                
                # æ“ä½œæŒ‰é’®
                with gr.Row():
                    preview_btn = gr.Button("âš¡ é«˜é€Ÿé¢„è§ˆ", variant="secondary", size="lg")
                    full_btn = gr.Button("ğŸ¯ GPUå…¨åŠ›è½¬å½•", variant="primary", size="lg")
                
                # ç®¡ç†æŒ‰é’®
                with gr.Row():
                    clear_cache_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç†ç¼“å­˜", variant="secondary")
                    gpu_monitor = gr.Textbox(
                        label="ğŸ® GPUçŠ¶æ€",
                        value=monitor_gpu_usage(),
                        interactive=False,
                        max_lines=1
                    )
            
            with gr.Column():
                # è½¬å½•ç»“æœ
                transcript_output = gr.Textbox(
                    label="ğŸ“ è½¬å½•ç»“æœ + æ€§èƒ½ç»Ÿè®¡",
                    lines=25,
                    show_copy_button=True,
                    placeholder="GPUä¼˜åŒ–è½¬å½•ç»“æœå’Œè¯¦ç»†æ€§èƒ½ç»Ÿè®¡..."
                )
                
                # ä¿å­˜å’Œæ€»ç»“åŠŸèƒ½
                with gr.Row():
                    save_btn = gr.Button("ğŸ’¾ ä¿å­˜è½¬å½•æ–‡æœ¬", variant="secondary")
                    summary_btn = gr.Button("ğŸ¤– AIæ€»ç»“", variant="primary")
                
                save_status = gr.Textbox(
                    label="ä¿å­˜çŠ¶æ€",
                    interactive=False,
                    max_lines=2,
                    visible=False
                )
                
                # API Keyé…ç½®åŒºåŸŸ
                api_status, api_key_input = create_api_status_components()
                
                # æ€»ç»“ç»“æœæ˜¾ç¤º
                summary_output = gr.Textbox(
                    label="ğŸ¤– AIæ€»ç»“ç»“æœ",
                    lines=15,
                    show_copy_button=True,
                    placeholder="AIæ€»ç»“å°†åœ¨è¿™é‡Œæ˜¾ç¤º...",
                    visible=False
                )
                
                # ä¿å­˜AIæ€»ç»“æŒ‰é’®
                save_summary_btn = gr.Button("ğŸ’¾ ä¿å­˜AIæ€»ç»“", variant="secondary", visible=False)
                save_summary_status = gr.Textbox(
                    label="AIæ€»ç»“ä¿å­˜çŠ¶æ€",
                    interactive=False,
                    max_lines=2,
                    visible=False
                )
        
        # æ€§èƒ½è¯´æ˜
        with gr.Accordion("âš¡ GPUä¼˜åŒ–è¯´æ˜", open=False):
            gr.Markdown(create_performance_info())
        
        # äº‹ä»¶ç»‘å®š
        def setup_event_handlers():
            """è®¾ç½®äº‹ä»¶å¤„ç†å™¨"""
            
            # è½¬å½•äº‹ä»¶
            preview_btn.click(
                fn=lambda *args: transcribe_high_utilization(*args, preview_mode=True),
                inputs=[audio_input, model_input, language_input],
                outputs=[transcript_output, gr.State(), gpu_monitor]
            )
            
            full_btn.click(
                fn=lambda *args: transcribe_high_utilization(*args, preview_mode=False),
                inputs=[audio_input, model_input, language_input],
                outputs=[transcript_output, gr.State(), gpu_monitor]
            )
            
            # ç¼“å­˜æ¸…ç†
            clear_cache_btn.click(
                fn=clear_all_cache,
                outputs=[gpu_monitor]
            )
            
            # ä¿å­˜è½¬å½•æ–‡æœ¬
            save_btn.click(
                fn=save_transcript_with_dialog,
                inputs=[transcript_output],
                outputs=[save_status]
            ).then(
                fn=lambda: gr.update(visible=True),
                outputs=[save_status]
            )
            
            # AIæ€»ç»“ç›¸å…³äº‹ä»¶
            def start_summary():
                return gr.update(value="ğŸ¤– æ­£åœ¨ç”ŸæˆAIæ€»ç»“ï¼Œè¯·ç¨å€™...", visible=True), gr.update(visible=False)
            
            def show_summary_button(summary_result):
                if summary_result and not summary_result.startswith("âŒ") and "æ­£åœ¨ç”ŸæˆAIæ€»ç»“" not in summary_result:
                    return gr.update(visible=True)
                else:
                    return gr.update(visible=False)
            
            summary_btn.click(
                fn=start_summary,
                outputs=[summary_output, save_summary_btn]
            ).then(
                fn=summarize_with_deepseek,
                inputs=[transcript_output, api_key_input],
                outputs=[summary_output]
            ).then(
                fn=show_summary_button,
                inputs=[summary_output],
                outputs=[save_summary_btn]
            )
            
            # ä¿å­˜AIæ€»ç»“
            save_summary_btn.click(
                fn=save_summary_with_dialog,
                inputs=[summary_output],
                outputs=[save_summary_status]
            ).then(
                fn=lambda: gr.update(visible=True),
                outputs=[save_summary_status]
            )
        
        setup_event_handlers()
    
    return demo

if __name__ == "__main__":
    print("å¯åŠ¨GPUé«˜åˆ©ç”¨ç‡ä¼˜åŒ–æœåŠ¡...")
    
    # GPUé¢„çƒ­å’Œä¼˜åŒ–
    if torch.cuda.is_available():
        print("GPUé¢„çƒ­å’Œç¼–è¯‘ä¼˜åŒ–...")
        try:
            dummy = torch.randn(1, 1000, device="cuda:0")
            _ = dummy @ dummy.T
            del dummy
            torch.cuda.empty_cache()
            print("GPUé¢„çƒ­å®Œæˆ")
        except Exception as e:
            print(f"GPUé¢„çƒ­è·³è¿‡: {e}")
    
    # å¯åŠ¨åº”ç”¨
    demo = main()
    demo.launch(
        server_name="0.0.0.0",
        server_port=APP_PORT,
        share=True,
        show_error=True,
        max_file_size=MAX_FILE_SIZE
    )